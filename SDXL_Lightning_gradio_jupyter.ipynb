{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/SDXL-Lightning-jupyter/blob/main/SDXL_Lightning_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "#https://huggingface.co/spaces/AP123/SDXL-Lightning/blob/refs%2Fpr%2F1/app.py modified\n",
        "\n",
        "!pip install diffusers accelerate gradio\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "from diffusers import StableDiffusionXLPipeline, EulerDiscreteScheduler\n",
        "from huggingface_hub import hf_hub_download\n",
        "import spaces\n",
        "\n",
        "\n",
        "# Constants\n",
        "base = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "repo = \"ByteDance/SDXL-Lightning\"\n",
        "checkpoints = {\n",
        "    \"1-Step\" : [\"sdxl_lightning_1step_unet_x0.pth\", 1],\n",
        "    \"2-Step\" : [\"sdxl_lightning_2step_unet.pth\", 2],\n",
        "    \"4-Step\" : [\"sdxl_lightning_4step_unet.pth\", 4],\n",
        "    \"8-Step\" : [\"sdxl_lightning_8step_unet.pth\", 8],\n",
        "}\n",
        "\n",
        "\n",
        "# Ensure model and scheduler are initialized in GPU-enabled function\n",
        "if torch.cuda.is_available():\n",
        "    pipe = StableDiffusionXLPipeline.from_pretrained(base, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
        "\n",
        "\n",
        "# Function \n",
        "@spaces.GPU(enable_queue=True)\n",
        "def generate_image(prompt, ckpt):\n",
        "\n",
        "    checkpoint = checkpoints[ckpt][0]\n",
        "    num_inference_steps = checkpoints[ckpt][1] \n",
        "\n",
        "    if num_inference_steps==1:\n",
        "        # Ensure sampler uses \"trailing\" timesteps and \"sample\" prediction type for 1-step inference.\n",
        "        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", prediction_type=\"sample\")\n",
        "    else:\n",
        "        # Ensure sampler uses \"trailing\" timesteps.\n",
        "        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")\n",
        "        \n",
        "    pipe.unet.load_state_dict(torch.load(hf_hub_download(repo, checkpoint), map_location=\"cuda\"))\n",
        "    image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=0).images[0]\n",
        "    return image\n",
        "\n",
        "\n",
        "# Gradio Interface\n",
        "description = \"\"\"\n",
        "This demo utilizes the SDXL-Lightning model by ByteDance, which is a fast text-to-image generative model capable of producing high-quality images in 4 steps.\n",
        "As a community effort, this demo was put together by AngryPenguin. Link to model: https://huggingface.co/ByteDance/SDXL-Lightning\n",
        "\"\"\"\n",
        "\n",
        "css = \"\"\"\n",
        ".gradio-container {\n",
        "  max-width: 690px! important;\n",
        "}\n",
        "\n",
        "#share-btn-container{padding-left: 0.5rem !important; padding-right: 0.5rem !important; background-color: #000000; justify-content: center; align-items: center; border-radius: 9999px !important; max-width: 13rem; margin-left: auto;margin-top: 0.35em;}\n",
        "div#share-btn-container > div {flex-direction: row;background: black;align-items: center}\n",
        "#share-btn-container:hover {background-color: #060606}\n",
        "#share-btn {all: initial; color: #ffffff;font-weight: 600; cursor:pointer; font-family: 'IBM Plex Sans', sans-serif; margin-left: 0.5rem !important; padding-top: 0.5rem !important; padding-bottom: 0.5rem !important;right:0;font-size: 15px;}\n",
        "#share-btn * {all: unset}\n",
        "#share-btn-container div:nth-child(-n+2){width: auto !important;min-height: 0px !important;}\n",
        "#share-btn-container .wrap {display: none !important}\n",
        "#share-btn-container.hidden {display: none!important}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.HTML(\"<h1><center>Text-to-Image with SDXL Lightning âš¡</center></h1>\")\n",
        "    gr.Markdown(description)\n",
        "    with gr.Group():\n",
        "        with gr.Row():\n",
        "            prompt = gr.Textbox(label='Enter you image prompt:', scale=8)\n",
        "            ckpt = gr.Dropdown(label='Select Inference Steps',choices=['1-Step', '2-Step', '4-Step', '8-Step'], value='4-Step', interactive=True)\n",
        "            submit = gr.Button(scale=1, variant='primary')\n",
        "    img = gr.Image(label='SDXL-Lightening Generate Image')\n",
        "\n",
        "    prompt.submit(fn=generate_image,\n",
        "                 inputs=[prompt, ckpt],\n",
        "                 outputs=img,\n",
        "                 )\n",
        "    submit.click(fn=generate_image,\n",
        "                 inputs=[prompt, ckpt],\n",
        "                 outputs=img,\n",
        "                 )\n",
        "    \n",
        "demo.queue().launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
